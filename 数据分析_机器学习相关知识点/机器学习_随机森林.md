### 随机森林

- **集成学习的概念：**

构建多个弱分类器，讲他们的预测结果通过一定方式集成起来，作为最终预测结果


- **原理：**

  1. 创造一个由多个决策树组成的森林
  2. 每个决策树的训练样本用Bagging (Bootstrap Aggregation，即随机可重复地挑选和原样本量一样大的样本)选出 - **此为随机森林的第一个随机性**
  3. 每个决策树使用的特征的选取：设总样本中所含特征数量为M，随机取m << M大小的子特征集，从m个特征中根据GINI Index进行分叉，并且不剪树枝（Pruning） - **此为随机森林第二个随机性**
  4. 整个森林的Prediction用每个数的Prediction一起投票


  - 随机森林是一种Ensemble Method
  - Bootstrap的统计学原理：在可重复地随机抽取的情况下，抽样样本的分布与总分布一致(Sample Distribution = Population Distribution)
  - 随机特征抽取很好地解决了样本高维度问题
  - 整个Ensemble解决了单一决策树很容易出现的过拟合问题
